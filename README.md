# DeepASMR GAN ğŸ˜´
**Aiffel Mini-Hackerton <10.13 ~ 10.15>**
<img style="margin-top: 20px" src='./images/img1.PNG'> </img>
<img src='./images/img17.PNG'> </img>


## í”„ë¡œì íŠ¸ ìš”ì•½ 

### *completed*

- [ë°ì´í„° ì •ì˜](#data-definition)
- [ë°ì´í„° ìˆ˜ì§‘](#data-collection)
- [ë°ì´í„° ì „ì²˜ë¦¬](#data-preprocessing)
- [ìƒì„± ëª¨ë¸ êµ¬ì¶•](#generative-model)
- [ìŒì› ìƒì„± ë° ê²°ê³¼](#result)
- [ê³µê³µ ë¹…ë°ì´í„° ê³µëª¨ì „ PPT ì œì¶œ](#competition) 
---
### *In-progress*

- ì¥ë¥´ ë¶„ë¥˜ ëª¨ë¸ êµ¬ì¶•
-  ì¥ë¥´ ë¶„ë¥˜ ê²°ê³¼ ì‹œê°í™”(í´ëŸ¬ìŠ¤í„°ë§)
-  ì›¹ ì–´í”Œë¦¬ì¼€ì´ì…˜ ì œì‘
-  ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•
-  MIDI ë°ì´í„° í™•ë³´ ë° ìŒì› ìƒì„±
-  ì˜¤ë””ì˜¤ ê²°í•© ë° í•©ì„±(Audio Concatenation & Synthesis)
---

 ## [Data Definition]()

<img style="margin-top: 20px" src='./images/img2.PNG'> </img>


### `ASMR Attributes`
```
1. id - asmrID
2. author - ì˜ìƒ ì œì‘ìëª…
3. title - ì €ì¥í•  íŒŒì¼ëª…
4. channel_url - ì˜ìƒ URL
5. publish_date - ì˜ìƒ ì—…ë¡œë“œì¼
6. genre -  {nature, mix, tap}ìœ¼ë¡œ êµ¬ë¶„ 
7. comment - ë§ì†Œë¦¬ í¬í•¨ ìœ ë¬´ {í¬í•¨:1, ë¯¸í¬í•¨: 0}
8. file_size - íŒŒì¼ í¬ê¸°
9. genre_keyword - ì¥ë¥´ì— ëŒ€í•œ ì¶”ê°€ì ì¸ ì •ë³´
10. description - ì˜ìƒ ì„¤ëª…
```

### `Youtube`
```
ex)
URL: GET,
/api/asmr/{asmrId}/youtube/

{
    data : {
        "id": 1,
        "author": "ì¹´ë¯¼Carmine",
        "title": "yt_nature_fire_20180619",
        "channel_url": "https://www.youtube.com/watch?v=2TrgSww4Wf8&t=8s",
        "publish_date": "20180619",
        "genre": "nature",
        "comment": "0",
        "file_size": "2147483",
        "genre_keyword": "fire",
        "description": "ğŸ”¥ ê³µë¶€í•  ë•Œ ë“£ëŠ” ì¥ì‘ íƒ€ëŠ” ì†Œë¦¬ / Fireplace sound"
    }
}
```
---

### `Public Data`

```
ex)
URL: GET,
/api/asmr/{asmrId}/public/

{
    data : {
        "id": 2,
        "author": "êµ­ë¦½ê³µì›ê³µë‹¨",
        "title": "pb_nature_snow_20191231"
        "channel_url": "http://s3-asia-east.amazonaws.com/asmr/1",
        "publish_date": "20191231",
        "genre": "nature",
        "comment": "0",
        "file_size": "100000",
        "genre_keyword": "snow",
        "description": "ìì—°ì¹˜ìœ ë™ì˜ìƒ_ë•ìœ ì‚°ë“±ì‚°ë¡œëˆˆë°ŸëŠ”ì†Œë¦¬"
    }
}
```
---
## [Data Collection]()
<img style="margin-top: 20px" src='./images/img3.PNG'> </img>

*ë°ì´í„° í¬ë¡¤ë§*
- Youtube ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê¸° ìœ„í•´ `pytube` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì›í•˜ëŠ” ì˜ìƒì˜ urlì„ ë°›ì•„ `mp4` íŒŒì¼ì„ ë‹¤ìš´ë°›ì„ ìˆ˜ ìˆê²Œ ê¸°ëŠ¥ì„ êµ¬í˜„
- ì˜¤ë””ì˜¤ ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ìœ„í•´ `pydub`ì™€ `ffmpeg` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©
- ê³ ìŒì§ˆë¡œì˜ ë³€í™˜ì„ ìœ„í•´ `mp4` í¬ë§·ì—ì„œ `wav` í¬ë§·ìœ¼ë¡œ ë³€ê²½
- [ê³µê³µë°ì´í„° í¬í„¸](https://www.data.go.kr/)ì˜ ASMR ë°ì´í„° ì´ 94ê°œ í™•ë³´ (ì•ë¶€ë¶„ ì¸íŠ¸ë¡œ 5ì´ˆ ì œê±° ì™„ë£Œ)  
<img style="margin-top: 20px" src='./images/img9.PNG'> </img>

---
## [Data Preprocessing]()
<img style="margin-top: 20px" src='./images/img4.PNG'> </img>

*ì°¸ê³  ë…¸íŠ¸ë¶*

- [1. Audio Processing](https://github.com/ithingv/ai_study/blob/main/Deep_Learning/Speech/Audio_Processing.ipynb)
- [2. Audio Classification](https://github.com/ithingv/ai_study/blob/main/Deep_Learning/Speech/Audio_Classification.ipynb)
- [3. Speech Synthesis](https://github.com/ithingv/ai_study/blob/main/Deep_Learning/Speech/Speech%20Synthesis.ipynb)


*ë°ì´í„° ì „ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤*
```
# ì´ë²ˆ ë¯¸ë‹ˆ í•´ì»¤í†¤ í”„ë¡œì íŠ¸ì—ì„œëŠ” 1ì°¨ì› sequence ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ìŒì›ì„ ìƒì„±í•˜ì˜€ìŒ
1. mp4 -> wav
2. duration = 30ì´ˆ ë‹¨ìœ„ë¡œ ë°ì´í„° chunk
3. sampling rate = 22500ë¡œ ì„¤ì •
4. Input: 1D Sequence (dtype=numpy.float32)

# 2D ë©œìŠ¤í™íŠ¸ë¡œê·¸ë¨ ë³€í™˜ì‹œ
1. mp4 -> wav
2. duration = 30ì´ˆ ë‹¨ìœ„ë¡œ ë°ì´í„° chunk 
3. Sampling, Normalization, Mu-Law Encoding
4. Fast Fourier Transform 
5. Input: Melspectrogram(2D)
```
---
## [Generative Model]()


### Model List
<img  src='./images/img10.PNG'> </img>

---

### í”„ë¡œì íŠ¸ì— ì‚¬ìš©í•œ ìµœì¢… ëª¨ë¸ ---> `Resnet + VAE`
<img style="margin-top: 20px" src='./images/img5.PNG'> </img>
<img  src='./images/img6.PNG'> </img>


# `Resnet`
<img style="margin-top: 20px" src='./images/img14.PNG'> </img>

```
class Resnet1DBlock(tf.keras.Model):
    def __init__(self, kernel_size, filters,type='encode'):
        super(Resnet1DBlock, self).__init__(name='')
    
        if type=='encode':
            self.conv1a = layers.Conv1D(filters, kernel_size, 2,padding="same")
            self.conv1b = layers.Conv1D(filters, kernel_size, 1,padding="same")
            self.norm1a = tfa.layers.InstanceNormalization()
            self.norm1b = tfa.layers.InstanceNormalization()
        if type=='decode':
            self.conv1a = layers.Conv1DTranspose(filters, kernel_size, 1,padding="same")
            self.conv1b = layers.Conv1DTranspose(filters, kernel_size, 1,padding="same")
            self.norm1a = tf.keras.layers.BatchNormalization()
            self.norm1b = tf.keras.layers.BatchNormalization()
        else:
            return None

    def call(self, input_tensor):
        x = tf.nn.relu(input_tensor)
        x = self.conv1a(x)
        x = self.norm1a(x)
        x = layers.LeakyReLU(0.4)(x)

        x = self.conv1b(x)
        x = self.norm1b(x)
        x = layers.LeakyReLU(0.4)(x)

        x += input_tensor
        return tf.nn.relu(x)
```

---
# `VAE`

<img style="margin-top: 20px" src='./images/img12.PNG'> </img>
<img style="margin-top: 20px" src='./images/img13.PNG'> </img>

```
class CVAE(tf.keras.Model):

    def __init__(self, latent_dim):
        super(CVAE, self).__init__()
        self.latent_dim = latent_dim
        self.encoder = tf.keras.Sequential(
            [
                tf.keras.layers.InputLayer(input_shape=(1,22500*30)),# 90001
                layers.Conv1D(64,1,2),
                Resnet1DBlock(64,1),
                layers.Conv1D(128,1,2),
                Resnet1DBlock(128,1),
                layers.Conv1D(128,1,2),
                Resnet1DBlock(128,1),
                layers.Conv1D(256,1,2),
                Resnet1DBlock(256,1),
                # No activation
                layers.Flatten(),
                layers.Dense(latent_dim+latent_dim)

            ]
        )
        self.decoder = tf.keras.Sequential(
            [
                tf.keras.layers.InputLayer(input_shape=(latent_dim,)),
                layers.Reshape(target_shape=(1,latent_dim)),
                Resnet1DBlock(512,1,'decode'),
                layers.Conv1DTranspose(512,1,1),
                Resnet1DBlock(256,1,'decode'),
                layers.Conv1DTranspose(256,1,1),
                Resnet1DBlock(128,1,'decode'),
                layers.Conv1DTranspose(128,1,1),
                Resnet1DBlock(64,1,'decode'),
                layers.Conv1DTranspose(64,1,1),
                # No activation
                layers.Conv1DTranspose(22500*30,1,1), #90001
            ]
        )

    @tf.function
    def sample(self, eps=None):
        if eps is None:
            eps = tf.random.normal(shape=(200, self.latent_dim))
        return self.decode(eps, apply_sigmoid=True)

    @tf.function
    def encode(self, x):
        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)
        return mean, logvar

    @tf.function
    def reparameterize(self, mean, logvar):
        eps = tf.random.normal(shape=mean.shape)
        return eps * tf.exp(logvar * .5) + mean

    @tf.function
    def decode(self, z, apply_sigmoid=False):
        logits = self.decoder(z)
        if apply_sigmoid:
            probs = tf.sigmoid(logits)
            return probs
        return logits

    @tf.function
    def log_normal_pdf(sample, mean, logvar, raxis=1):
        log2pi = tf.math.log(2. * np.pi)
        return tf.reduce_sum(
             -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),axis=raxis)

    @tf.function
    def compute_loss(model, x):
        mean, logvar = model.encode(x)
        z = model.reparameterize(mean, logvar)
        x_logit = model.decode(z)
        cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)
        logpx_z = -tf.reduce_sum(cross_ent, axis=[1,2])
        logpz = log_normal_pdf(z, 0., 0.)
        logqz_x = log_normal_pdf(z, mean, logvar)
        return -tf.reduce_mean(logpx_z + logpz - logqz_x)
```
---
## [Result]()
<img style="margin-top: 20px" src='./images/img7.PNG'> </img>

ë¹—ì†Œë¦¬ ìŒì› ìƒì„±ê²°ê³¼ url: https://www.notion.so/1d04da9a35d943ec93b52716e6b7c4ef

---
## [Competition](#competition)
<img style="margin-top: 20px" src='./images/img16.PNG'> </img>
<img src='./images/img15.PNG'> </img>

- í™ˆí˜ì´ì§€ : https://www.data.go.kr/bbs/ntc/selectNotice.do?pageIndex=1&originId=NOTICE_0000000002205&atchFileId=
- 2021ë…„ ê³µê³µë¹…ë°ì´í„° ë¶„ì„ ê³µëª¨ì „ ê³µëª¨(~10.15) ì§€ì›ì„œ ì ‘ìˆ˜ ì™„ë£Œ
- [ìµœì¢… ì œì¶œ ì§€ì›ì„œ pdf](./docs/ASMR.pdf)





