<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DeepASMR Project 😴</title>
    <link rel="stylesheet" href="index.css" type="text/css">
    <script src="https://unpkg.com/wavesurfer.js"></script>
</head>
<body>
    <header class="section">
        <h1>DeepASMR 😴</h1>
    </header> 
    <section class="intro__contents">
        <div class="main__contents__list">
            <h4>Contents</h4>
            <ul class="models">
                <li><a href="#introduction">Project introduction</a></li>
                <li><a href="#introduction">Music Generation</a></li>
                <li><a href="#model-vae">Prior work</a></li>
                <li><a href="#model-wavenet">Midi vs Waveform</a></li>
                <li><a href="#model-vqvae">Web Demo</a></li>
                <li><a href="#model-melnet">Approach</a></li>
                <li><a href="#model-melnet">Generative Model</a></li>
                <li><a href="#model-melnet">Comments</a></li>
            </ul>
        </div>
        <div class="introduction">
            <h4>Proeject Introduction</h4>
                <p class="project__intro">ASMR(Autonomous Sensory Meridian Response)은 시각, 청각, 촉각 등의 경로로 심리적 안정이나 쾌감을 유발한다고 알려져 있다. 본 연구의 목적은 딥러닝 기술을 이용하여 청취자에게 정서적 안정감을 주는 ASMR을 제작하는 것을 목표한다. 최근 ASMR이 본격적으로 인기를 얻으면서 ASMR 효과에 대한 과학적 실험에 대한 연구 결과가 발표되고 있으며 소셜미디어 등에서 ASMR을 경험한 사용자들의 긍정적인 후기를 어렵지 않게 확인할 수 있다. 본 연구는 ASMR이 주는 안정감, 수면 유도, 집중력 향상 등의 효과에 집중하고 사용자의 선호도를 반영하여 새로운 ASMR을 생성하는 DeepASMR을 제안한다.</p>
        </div>

        <div class="abstraction">
            <h4>Abstraction</h4>
                <ul>
                    <li>Due to the large number of audio samples on this page, all samples have been compressed (96 kb/s mp3). The uncompressed files are available for download at <a href='https://github.com/audio-samples/audio-samples.github.io'>this repository</a>.</li>
                    <li>Audio clips which correspond to ground-truth data are generated by inverting ground-truth spectrograms.</li>
                    <li>Samples shown here were selected based on diversity and quality.  Samples used for quantitative experiments in the paper were randomly drawn.</li>
                </ul>
        </div>
        <div class="member">
            <div class="row">
                <div class="story">
                    figure
                </div>
            </div>
        </div>

    </section>
    <hr>

    <section class="contents">
        <div class="outer__container">
            <div class="sidebar">
                <div class="contents__list">
                    <p>Contents</p>
                    <li><a href="#motivation">Motivation and Prior Work</a></li>
                    <li><a href="#model-vae">VAE</a></li>
                    <li><a href="#model-wavenet">WAVENET</a></li>
                    <li><a href="#model-vqvae">VQ-VAE</a></li>
                    <li><a href="#model-melnet">Melnet</a></li>
                </div>
            </div>
            <div class="main_container">
            
                <div id="mir">
                    <h2>Music Generation Project</h2>
                    <ul>
                        <li style="font-weight: bold;"> Music Information Retrieval</li>
                        <p>음원 정보 복원(Music information retrival) 은 음원으로부터 정보를 추출하는 다양한 학문에 걸친 분야로 알려져 있다. MIR은 현실 세계에 다양하게 적용되며, 음악학(musicology), 음향심리학(psychoacoustics), 심리학, 신호처리(signal proecssing), 정보학(informatics), 특히 기계학습 분야에서 분류(Classification) 및 생성(Generation) 등의 형태로 다양하게 적용됩니다.  
                            그 중에서도 자동 음원 생성(automatic music generation) 의 분야는 많은 MIR 연구자들에게 도전적인 주제이며 현재까지 이러한 시도들은 제한된 성공으로 남아있다.</p>
                        <div class="img__container">
                            <img src="./images/mir.png" style="width:600px; height:300px;">
                        </div>   
                        <li style="font-weight: bold;">AI Music Generation</li>
                        <p>불과 얼마전만 하더라도 인공지능의 창조적 능력에 대한 의구심이 제기됐다. 인간과 기계를 구분하는 ‘감정’은 예술 분야에서 가장 중요한 요소이고 기계는 인간 고유의 영역인 감정을 이해하지 못한다는 의견이 많았다. 하지만 최근 음악 분야에서 글로벌 IT 기업을 필두로 딥러닝 기술을 활용해 음악 작곡에 도전하는 인공지능 프로젝트의 성과는 놀라움을 주고 있으며 “인공지능(AI)이 생산하는 음악의 진행 속도를 고려할 때, 10년 안에 수작업으로 작곡하는 것은 구식이 될 것으로 보인다.” 라는 전문가의 예측도 있다.</p>

                        <p>OpenAI의 <a href="https://openai.com/blog/musenet/">MuseNet</a>(2019), <a href="https://openai.com/blog/jukebox/">Jukebox</a>(2020) 그리고 Google의 <a href="https://magenta.tensorflow.org/">Magenta</a>(2017) 프로젝트는 이러한 딥러닝 방식을 가장 잘 활용한 대표적인 음악 인공지능이다. MuseNet은 <a href="https://openai.com/blog/better-language-models/">GPT-2</a>, <a href="https://openai.com/blog/sparse-transformer/">Sparse Transformer</a> 모델을 사용하여 많은 양의 MIDI 데이터를 학습하였고 10개 악기를 사용해 새로운 음악을 만들어 낸다. 그리고 Jukebox는 <a href="https://arxiv.org/abs/1906.00446">VQ-VAE-2</a> 모델을 기반으로 Waveform의 Long Range Structure와 High diversity를 이해하여 원본과 상당히 유사한 사운드를 생성할 수 있음을 보여주었다. </p>
                        <div class="gif__container">
                            <div class="magenta_gif">
                                <img src="./images/melody_mixer.gif" >
                                <p><a href="https://medium.com/@torinblankensmith/melody-mixer-using-deeplearn-js-to-mix-melodies-in-the-browser-8ad5b42b4d0b"></a></p>
                            </div>   
                            <div class="magenta_gif">
                                <img src="./images/Omens of Love Primer MIDI.gif" >
                                <p><a href="https://medium.com/@torinblankensmith/melody-mixer-using-deeplearn-js-to-mix-melodies-in-the-browser-8ad5b42b4d0b" ></a></p>
                            </div>    
                        </div>
                            <p>마지막으로 Google의 Magenta는 음악 시퀀스 데이터의 음악적 특성을 담아 요약된 잠재 벡터로 인코딩하고 그 후에 다시 음악 시퀀스로 디코딩하는 <a href="https://magenta.tensorflow.org/music-vae">MusicVAE</a> 모델을 사용하였다. 이러한 인공지능이 만들어낸 음악은 아직 인간이 만든 음악과는 구분이 되는 편이고 기존 음악보다 뛰어나다고 볼 수는 없다. 하지만 시간이 흐르고 점차 많은 음악 관련 데이터를 학습하고 컴퓨팅과 하드웨어의 발전이 동반되면 인공지능이 어떠한 음악을 만들어 낼 수 있을지 가늠하기 어렵다.</p>
                                <div class="img__container">
                                    <img src="./images/musicVae.png" style="width:600px; height:300px"/>
                                    <p class="img__font__color">MusicVAE</p>
                                </div>        
                    </ul>
                </div>
                <hr>
                <div id="prior">
                    <h2>Prior work</h2>                
                        <ul>
                            <li><a href="https://s-space.snu.ac.kr/handle/10371/175269">Deep Learning based ASMR</a></li>
                            <p>딥러닝을 이용하여 기존 ASMR 음원들을 모으고 분류하며 사용자의 선호도를 바탕으로 새로운 ASMR 음원을 생성할 수 있는 플랫폼인 DeepASMR을 제안한다. DeepASMR은 ASMR 음원 분류 및 인식을 위해 기존의 음악 인식이나 소음 인식을 위한 DNN보다 개선된 DNN 모델들을 구축하여 분류의 정확도를 95% 이상까지 높였다.
                            <div class="img__container">
                                <img src="./images/DNN.JPG">
                            </div>
                            <p>DNN을 기반으로 기존 ASMR 음원들을 변형하거나 합성하는 방식으로 새로운 ASMR 음원을 생산한다. 이를 위해 VAE(Variational Autoencoder) 및 GAN(Generative Adversarial Network) 방식을 이용하여 ASMR 음원 생성 DNN 모델을 구축하였다. 이를 통해 생성된 ASMR 음원들을 우리의 분류 DNN 모델에 입력하여 그 정확성을 검증한 결과, 70% 이상의 정확도를 보여 제안하는 DNN 모델이 양질의 ASMR 음원들을 생성하였음을 시사한다.</p>
                            <div class="img__container">
                                <img src="./images/VAE.JPG">
                            </div>
                        </ul>
                 
                    <hr>
                    <div class="youtube__container">
                        <ul>
                            <li>ASMR Generation Demo</li>
                        </ul>
                        <div class="video">
                            <iframe class="youtube" width="600" height="350"
                            src="https://www.youtube.com/embed/v9ND1fJYLpk">
                            </iframe>
                        </div>
                    </div>
                </div>
                <hr>
                <div id="dataset">
                    <div class="gif__container">
                        <div class="magenta_gif">
                            <img src="./images/midi.gif" >
                            <p><a href="https://medium.com/@torinblankensmith/melody-mixer-using-deeplearn-js-to-mix-melodies-in-the-browser-8ad5b42b4d0b"></a></p>
                        </div>   
                        <div class="magenta_gif">
                            <img src="./images/wave.gif" style="width: 500px">
                            <p><a href="https://medium.com/@torinblankensmith/melody-mixer-using-deeplearn-js-to-mix-melodies-in-the-browser-8ad5b42b4d0b" ></a></p>
                        </div>    
                    </div>
                    
                </div>
                <div id="midi_wave">
                    <h2>Dataset</h2>      
                </div>

                <hr>
                
                <div id="model-vae" class="section">
                    <h2>VAE</h2>
                        <ul>
                            <li>VAE</li>
                        </ul>
                    <div class="row">
                        <div class="column_2">
                            <div id='player-3' class='player'>
                                <div class='spectrogram'>
                                    <div class='controls'>
                                        <p>
                                            Audio Genre:
                                            <select id='select-genre'>
                                              <option value="Rain">rain</option>
                                              <option value="Fire">fire</option>
                                              <option value="Wave">wave</option>
                                              <option value="Wind">wind</option>
                                            </select>
                                        </p><span class="audio_detail">Original Audio</span>
                
                                    </div>
                                    <div class='overlay'>
                                        <img src='/images/sample-0.png'>
                                    </div>
                                    <div class='audio-controls'>
                                        <button id="playpause" disabled class='playpause' title="play">
                                            <svg class='play-img' width="14px" height="19px" viewBox="0 0 14 19">
                                                <polygon id="Triangle" fill="#000000" transform="translate(9, 9.5) rotate(90) translate(-7, -9.5) " points="7 2.5 16.5 16.5 -2.5 16.5"></polygon>
                                            </svg>
                                            <svg class='pause-img' width="16px" height="19px" viewBox="0 0 16 19">
                                                <g fill="#000000" stroke="#000000">
                                                    <rect id="Rectangle" x="0.5" y="0.5" width="4" height="18"></rect>
                                                    <rect id="Rectangle" x="11.5" y="0.5" width="4" height="18"></rect>
                                                </g>
                                            </svg>
                                        </button>
                
                                        <audio id='play-1' class='play'>
                                            <source id='src1' src='samples/figs/ted_speakers/BillGates/sample-0.ogg' type='audio/ogg'>
                                            <source id='src2' src='/audio/0.wav' type='audio/wav'>
                                        </audio>
                                        <div class='response'>
                                            <canvas class='response-canvas'></canvas>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>

                        <div class="column_2">
                            <div id='player-3' class='player'>
                                <div class='spectrogram'>
                                    <div class='controls'>
                                        <p>
                                            <br>
                                        </p><span class="audio_detail">Sampled Audio</span>
                                    </div>
                                    <div class='overlay'>
                                        <img  class='audio_img' src='/images/sample-0.png'>
                                        <div id="waveform"></div>
                                        <div class="controls">
                                            <img src="images/play.png" id="playBtn">
                                            <img src="images/stop.png" id="stopBtn">
                                            <img src="images/volume.png" id="volumeBtn">
                                        </div>
                                    </div>                                    
                                </div>
                            </div>                       
                        </div>
                    </div>
                </div>
                
                <hr>

                <div id="model-wavenet" class="section">
                    <h2>WAVENET</h2>
                    <ul>
                        <li>WAVENET 설명</li>
                    </ul>
                    <div class="playlist">
                        <div class="labeled-audio"><audio preload="metadata" controls><source src='./0.wav' type='audio/wav'></audio></div>
                        <div class="labeled-audio"><audio preload="metadata" controls><source src='./0.wav' type='audio/wav'></audio></div>
                        <div class="labeled-audio"><audio preload="metadata" controls><source src='./0.wav' type='audio/wav'></audio></div>
                        <div class="labeled-audio"><audio preload="metadata" controls><source src='./0.wav' type='audio/wav'></audio></div>
                    </div>
                </div>

                <hr>

                <div id="model-vqvae" class="section">
                    <h2>VQ-VAE</h2>
                    <ul>
                        <li>VQ-VAE 설명</li>
                    </ul>
                    <div class="playlist">
                        <div class="labeled-audio"><audio preload="metadata" controls><source src='./0.wav' type='audio/wav'></audio></div>
                        <div class="labeled-audio"><audio preload="metadata" controls><source src='./0.wav' type='audio/wav'></audio></div>
                        <div class="labeled-audio"><audio preload="metadata" controls><source src='./0.wav' type='audio/wav'></audio></div>
                        <div class="labeled-audio"><audio preload="metadata" controls><source src='./0.wav' type='audio/wav'></audio></div>
                    </div>
                </div>
                
                <hr>

                <div id="model-melnet" class="section">
                    <h2>Melnet</h2>
                    <ul>
                        <li>Melnet 설명</li>
                    </ul>
                    <div class="playlist">
                        <div class="labeled-audio"><audio preload="metadata" controls><source src='./0.wav' type='audio/wav'></audio></div>
                        <div class="labeled-audio"><audio preload="metadata" controls><source src='./0.wav' type='audio/wav'></audio></div>
                        <div class="labeled-audio"><audio preload="metadata" controls><source src='./0.wav' type='audio/wav'></audio></div>
                        <div class="labeled-audio"><audio preload="metadata" controls><source src='./0.wav' type='audio/wav'></audio></div>
                    </div>
                </div>
            </div>
    </section>

    <script>
    var wavesurfer = WaveSurfer.create({
        container: '#waveform',
        waveColor: '#dde5ec',
        progressColor: '#03cebf',
        barWidth: 4,
        height: 90,
        responsive: true,
        hideScrollbar: true,
        barRadius: 4
        });

        wavesurfer.load('audio/0.wav');

        var playBtn = document.getElementById('playBtn');
        var stopBtn = document.getElementById('stopBtn');
        var volumeBtn = document.getElementById('volumeBtn');
        
        playBtn.onclick = function(){
            wavesurfer.playPause();
            if(playBtn.src.includes("play.png")){
                playBtn.src = "images/pause.png";
            } else {
                playBtn.src = "images/play.png";
            }
        }

        stopBtn.onclick = function(){
            wavesurfer.stop();
            playBtn.src = "images/play.png";
        }

        volumeBtn.onclick = function(){
            wavesurfer.toggleMute();
            if(volumeBtn.src.includes("volume.png")){
                volumeBtn.src = "images/mute.png";
            } else {
                volumeBtn.src = "images/volume.png";
            }
        }

        wavesurfer.on('finish', function(){
            playBtn.src = "images/play.png"
            wavesurfer.stop();
        })

    </script>


</body>
</html>