{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af52c6e0",
   "metadata": {},
   "source": [
    "# VQ VAE\n",
    "\n",
    "`VQ-VAE` where we use discrete latent variables with a new way of\n",
    "training, inspired by vector quantisation (VQ). The posterior and prior distributions are categorical,\n",
    "and the samples drawn from these distributions index an embedding table. These embeddings are\n",
    "then used as input into the decoder network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef9a8e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-04 11:21:03.557157: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "# tensorflow \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Add\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d501c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython import display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a1e00aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-04 10:52:49.684697: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-04 10:52:49.685892: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-04 10:52:49.707967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-04 10:52:49.708284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-12-04 10:52:49.708307: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-04 10:52:49.711167: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-12-04 10:52:49.711240: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-12-04 10:52:49.712428: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-04 10:52:49.712743: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-04 10:52:49.715922: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-04 10:52:49.716689: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-12-04 10:52:49.716858: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-12-04 10:52:49.716963: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-04 10:52:49.717273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-04 10:52:49.717498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "# gpu check\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40db8bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(layers.Layer):\n",
    "    def __init__(self, kernel_size, filters, type='encode'):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "    \n",
    "        if type=='encode':\n",
    "            self.conv1 = layers.Conv1D(filters, kernel_size, 2,padding=\"same\")\n",
    "            self.conv2 = layers.Conv1D(filters, kernel_size, 1,padding=\"same\")\n",
    "            self.norm1 = layers.BatchNormalization()\n",
    "            self.norm2 = layers.BatchNormalization()\n",
    "        if type=='decode':\n",
    "            self.conv1 = layers.Conv1DTranspose(filters, kernel_size, 1,padding=\"same\")\n",
    "            self.conv2 = layers.Conv1DTranspose(filters, kernel_size, 1,padding=\"same\")\n",
    "            self.norm1 = layers.BatchNormalization()\n",
    "            self.norm2 = layers.BatchNormalization()\n",
    "        else:\n",
    "            return None\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        x = tf.nn.relu(inputs)\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = layers.LeakyReLU(0.4)(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = layers.LeakyReLU(0.4)(x)\n",
    "\n",
    "        x = Add()([x, inputs])\n",
    "        x = tf.nn.relu(x)\n",
    "        return x      \n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_mean)))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "# Labmda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa926e16",
   "metadata": {},
   "source": [
    "# VectorQuantizer layer\n",
    "\n",
    "- 커스텀 레이어 구현\n",
    "    - vq_vae 모델의 핵심 요소인 vector quantizer 로직을 캡슐화\n",
    "    - Encoder 아웃풋: `(batch_size, height, width, num_channels)`\n",
    "    -  VectorQuntizer는 num_channels를 제외한 인코더의 아웃풋의 나머지 차원을 `flatten`함\n",
    "    - `(batch_size * height * width, num_channels)`\n",
    "    - `num_channels`를 잠재 임베딩을 위한 공간으로 설정\n",
    "\n",
    "- Embedding Table\n",
    "    - codebook을 학습하기 위해 초기화\n",
    "    - flatten된 encoder의 output과 이 codebook의 code words(e_k) 사이의  `L2-normalized distance`를 사용하여 minimum distance를 계산\n",
    "    - quantization을 위해 `one-hot-encoding` 적용\n",
    "    - encoder output과 가장 가까운 code의 경우 1로 나머지들은 0으로 맵핑\n",
    "\n",
    "- quantization process `미분불가`\n",
    "    - decoder와 encoder 사이의 `straight-through estimator` 적용\n",
    "    - decoder의 gradients가 직접 encoder로 전파되도록 한다.\n",
    "    - encoder와 decoder가 같은 `channel_space(=D)` 차원을 가지며 decoder의 gradients는 어떻게 encoder가 reconstruction loss를 줄일 수 있는지에 대한 유용한 정보를 포함한다.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "103aeda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorQuantizer(layers.Layer):\n",
    "    def __init__(self, num_embeddings, embedding_dim, beta=0.25, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.beta = (\n",
    "            beta  # This parameter is best kept between [0.25, 2] as per the paper.\n",
    "        )\n",
    "\n",
    "        # Initialize the embeddings which we will quantize.\n",
    "        w_init = tf.random_uniform_initializer()\n",
    "        self.embeddings = tf.Variable(\n",
    "            initial_value=w_init(\n",
    "                shape=(self.embedding_dim, self.num_embeddings), dtype=\"float32\"\n",
    "            ),\n",
    "            trainable=True,\n",
    "            name=\"embeddings_vqvae\",\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        # Calculate the input shape of the inputs and\n",
    "        # then flatten the inputs keeping `embedding_dim` intact.\n",
    "        input_shape = tf.shape(x)\n",
    "        flattened = tf.reshape(x, [-1, self.embedding_dim])\n",
    "\n",
    "        # Quantization.\n",
    "        encoding_indices = self.get_code_indices(flattened)\n",
    "        encodings = tf.one_hot(encoding_indices, self.num_embeddings)\n",
    "        quantized = tf.matmul(encodings, self.embeddings, transpose_b=True)\n",
    "        quantized = tf.reshape(quantized, input_shape)\n",
    "\n",
    "        # Calculate vector quantization loss and add that to the layer. You can learn more\n",
    "        # about adding losses to different layers here:\n",
    "        # https://keras.io/guides/making_new_layers_and_models_via_subclassing/. Check\n",
    "        # the original paper to get a handle on the formulation of the loss function.\n",
    "        commitment_loss = self.beta * tf.reduce_mean(\n",
    "            (tf.stop_gradient(quantized) - x) ** 2\n",
    "        )\n",
    "        codebook_loss = tf.reduce_mean((quantized - tf.stop_gradient(x)) ** 2)\n",
    "        self.add_loss(commitment_loss + codebook_loss)\n",
    "\n",
    "        # Straight-through estimator.\n",
    "        quantized = x + tf.stop_gradient(quantized - x)\n",
    "        return quantized\n",
    "\n",
    "    def get_code_indices(self, flattened_inputs):\n",
    "        # Calculate L2-normalized distance between the inputs and the codes.\n",
    "        similarity = tf.matmul(flattened_inputs, self.embeddings)\n",
    "        distances = (\n",
    "            tf.reduce_sum(flattened_inputs ** 2, axis=1, keepdims=True)\n",
    "            + tf.reduce_sum(self.embeddings ** 2, axis=0)\n",
    "            - 2 * similarity\n",
    "        )\n",
    "\n",
    "        # Derive the indices for minimum distances.\n",
    "        encoding_indices = tf.argmin(distances, axis=1)\n",
    "        return encoding_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece5e9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder(latent_dim=2):\n",
    "    encoder_inputs = keras.Input(shape=(28, 28, 1)) # (1, 44100 * 10)\n",
    "    x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(\n",
    "        encoder_inputs\n",
    "    )\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    encoder_outputs = layers.Conv2D(latent_dim, 1, padding=\"same\")(x)\n",
    "    return keras.Model(encoder_inputs, encoder_outputs, name=\"encoder\")\n",
    "\n",
    "\n",
    "def get_decoder(latent_dim=2):\n",
    "    latent_inputs = keras.Input(shape=get_encoder().output.shape[1:])\n",
    "    x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(\n",
    "        latent_inputs\n",
    "    )\n",
    "    x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    decoder_outputs = layers.Conv2DTranspose(1, 3, padding=\"same\")(x)\n",
    "    return keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d42aa56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-04 11:21:41.870735: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-04 11:21:41.871929: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-04 11:21:41.900071: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-04 11:21:41.900445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-12-04 11:21:41.900468: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-04 11:21:41.903384: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-12-04 11:21:41.903455: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-12-04 11:21:41.904667: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-04 11:21:41.905056: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-04 11:21:41.908166: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-04 11:21:41.909014: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-12-04 11:21:41.909173: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-12-04 11:21:41.909287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-04 11:21:41.909623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-04 11:21:41.909860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-12-04 11:21:41.910465: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-04 11:21:41.910605: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-04 11:21:41.910912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-12-04 11:21:41.910935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-04 11:21:41.910961: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-12-04 11:21:41.910973: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-12-04 11:21:41.910985: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-04 11:21:41.910996: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-04 11:21:41.911008: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-04 11:21:41.911019: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-12-04 11:21:41.911031: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-12-04 11:21:41.911110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-04 11:21:41.911412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-04 11:21:41.911639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-12-04 11:21:41.911685: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-04 11:21:42.594551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-04 11:21:42.594599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-12-04 11:21:42.594607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-12-04 11:21:42.594906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-04 11:21:42.595283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-04 11:21:42.595598: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-04 11:21:42.595878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 193 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n"
     ]
    }
   ],
   "source": [
    "encoder = get_encoder()\n",
    "decoder = get_decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fcf5edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 7, 7, 2) dtype=float32 (created by layer 'conv2d_2')>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486c466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vqvae(latent_dim=16, num_embeddings=64):\n",
    "    vq_layer = VectorQuantizer(num_embeddings, latent_dim, name=\"vector_quantizer\")\n",
    "    encoder = get_encoder(latent_dim)\n",
    "    decoder = get_decoder(latent_dim)\n",
    "    inputs = keras.Input(shape=(28, 28, 1))\n",
    "    encoder_outputs = encoder(inputs)\n",
    "    quantized_latents = vq_layer(encoder_outputs)\n",
    "    reconstructions = decoder(quantized_latents)\n",
    "    return keras.Model(inputs, reconstructions, name=\"vq_vae\")\n",
    "\n",
    "\n",
    "get_vqvae().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae74908",
   "metadata": {},
   "source": [
    "### 손실함수\n",
    "\n",
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23098fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQVAETrainer(keras.models.Model):\n",
    "    def __init__(self, train_variance, latent_dim=32, num_embeddings=128, **kwargs):\n",
    "        super(VQVAETrainer, self).__init__(**kwargs)\n",
    "        self.train_variance = train_variance\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "\n",
    "        self.vqvae = get_vqvae(self.latent_dim, self.num_embeddings)\n",
    "\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.vq_loss_tracker = keras.metrics.Mean(name=\"vq_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.vq_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, x):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Outputs from the VQ-VAE.\n",
    "            reconstructions = self.vqvae(x)\n",
    "\n",
    "            # Calculate the losses.\n",
    "            reconstruction_loss = (\n",
    "                tf.reduce_mean((x - reconstructions) ** 2) / self.train_variance\n",
    "            )\n",
    "            total_loss = reconstruction_loss + sum(self.vqvae.losses)\n",
    "\n",
    "        # Backpropagation.\n",
    "        grads = tape.gradient(total_loss, self.vqvae.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.vqvae.trainable_variables))\n",
    "\n",
    "        # Loss tracking.\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.vq_loss_tracker.update_state(sum(self.vqvae.losses))\n",
    "\n",
    "        # Log results.\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"vqvae_loss\": self.vq_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc59f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/home/jsryu1228/crawling/temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d093c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "\n",
    "asmr_list = np.array(natsorted(os.listdir(BASE_DIR)))\n",
    "train_data = [BASE_DIR + '/%s' % (x) for x in asmr_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d924ed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 파일이 10초가 아닐 수 있기 때문에 제거\n",
    "train_data = train_data[:len(train_data) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b6f479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav_load(asmr):\n",
    "    y, sampling_rate = librosa.load(asmr, sr=44100, offset=0.0, duration=10)\n",
    "    y = y.reshape(1,44100*10)\n",
    "    return y\n",
    "\n",
    "map_func = lambda file: tf.compat.v1.py_func(wav_load, [file], [tf.float32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2666f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(train_data)\n",
    "    .map(map_func, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(8)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
