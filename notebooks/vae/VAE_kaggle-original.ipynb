{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4a7cfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-09 03:20:32.406975: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "# tensorflow \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Add\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d1bf7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsryu1228/anaconda3/envs/asmr/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.5.0 and strictly below 2.8.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.4.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython import display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "373bab79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-09 03:20:35.309792: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-09 03:20:35.311552: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-09 03:20:35.929829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-09 03:20:35.930536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-12-09 03:20:35.930582: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-09 03:20:35.934269: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-12-09 03:20:35.934417: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-12-09 03:20:35.936014: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-09 03:20:35.936487: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-09 03:20:35.940368: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-09 03:20:35.941327: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-12-09 03:20:35.941535: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-12-09 03:20:35.941687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-09 03:20:35.942378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-09 03:20:35.942954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "# gpu check\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cd131c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 60000\n",
    "BATCH_SIZE = 10\n",
    "test_size = 10000\n",
    "epochs = 20\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "latent_dim = 2\n",
    "num_examples_to_generate = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a218abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1052b8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-09 03:20:42.808406: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-09 03:20:42.808843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-09 03:20:42.809703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-12-09 03:20:42.809778: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-09 03:20:42.809882: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-12-09 03:20:42.809918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-12-09 03:20:42.809945: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-09 03:20:42.809969: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-09 03:20:42.809992: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-09 03:20:42.810015: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-12-09 03:20:42.810039: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-12-09 03:20:42.810213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-09 03:20:42.811000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-09 03:20:42.811633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-12-09 03:20:42.811708: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_3219/2875824582.py:5: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-09 03:20:43.617320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-09 03:20:43.617386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-12-09 03:20:43.617398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-12-09 03:20:43.617838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-09 03:20:43.618746: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-09 03:20:43.619518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-09 03:20:43.620214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14762 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n"
     ]
    }
   ],
   "source": [
    "# seed=123\n",
    "# tf.compat.v1.set_random_seed(seed)\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552c19bd",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2736b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/home/jsryu1228/crawling/temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24563529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 파일이 10초가 아닐 수 있기 때문에 제거\n",
    "from natsort import natsorted\n",
    "\n",
    "asmr_list = np.array(natsorted(os.listdir(BASE_DIR)))\n",
    "train_data = [BASE_DIR + '/%s' % (x) for x in asmr_list]\n",
    "train_data = train_data[:len(train_data) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c52cfb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data[:378]\n",
    "test = train_data[378:]\n",
    "\n",
    "assert len(train) == len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7da450b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 9] Bad file descriptor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3219/4236005992.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m22500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mipd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m22500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/asmr/lib/python3.7/site-packages/IPython/lib/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, filename, url, embed, rate, autoplay, normalize, element_id)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melement_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/asmr/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/asmr/lib/python3.7/site-packages/IPython/lib/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mmimetypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/asmr/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 9] Bad file descriptor"
     ]
    }
   ],
   "source": [
    "sample = librosa.load(train_data[2], sr=22500)\n",
    "ipd.Audio(sample, 22500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b17885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav_load(asmr):\n",
    "    y, sampling_rate = librosa.load(asmr, sr=22500, offset=0.0, duration=10)\n",
    "    y = y.reshape(1,22500*10)\n",
    "    return y\n",
    "\n",
    "map_func = lambda file: tf.compat.v1.py_func(wav_load, [file], [tf.float32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d5f993",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(train)\n",
    "    .map(map_func, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    ")\n",
    "\n",
    "test = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(test)\n",
    "    .map(map_func, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85c94ef",
   "metadata": {},
   "source": [
    "## Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002d4f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet1DBlock(tf.keras.Model):\n",
    "    def __init__(self, kernel_size, filters,type='encode'):\n",
    "        super(Resnet1DBlock, self).__init__(name='')\n",
    "    \n",
    "        if type=='encode':\n",
    "            self.conv1a = layers.Conv1D(filters, kernel_size, 2,padding=\"same\")\n",
    "            self.conv1b = layers.Conv1D(filters, kernel_size, 1,padding=\"same\")\n",
    "            self.norm1a = tfa.layers.InstanceNormalization()\n",
    "            self.norm1b = tfa.layers.InstanceNormalization()\n",
    "        if type=='decode':\n",
    "            self.conv1a = layers.Conv1DTranspose(filters, kernel_size, 1,padding=\"same\")\n",
    "            self.conv1b = layers.Conv1DTranspose(filters, kernel_size, 1,padding=\"same\")\n",
    "            self.norm1a = tf.keras.layers.BatchNormalization()\n",
    "            self.norm1b = tf.keras.layers.BatchNormalization()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        x = tf.nn.relu(input_tensor)\n",
    "        x = self.conv1a(x)\n",
    "        x = self.norm1a(x)\n",
    "        x = layers.LeakyReLU(0.4)(x)\n",
    "\n",
    "        x = self.conv1b(x)\n",
    "        x = self.norm1b(x)\n",
    "        x = layers.LeakyReLU(0.4)(x)\n",
    "\n",
    "        x += input_tensor\n",
    "        return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d727b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "    \"\"\"Convolutional variational autoencoder.\"\"\"\n",
    "\n",
    "    def __init__(self, latent_dim):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(1,22500*10)),# 90001\n",
    "                layers.Conv1D(64,1,2),\n",
    "                Resnet1DBlock(64,1),\n",
    "                layers.Conv1D(128,1,2),\n",
    "                Resnet1DBlock(128,1),\n",
    "                layers.Conv1D(128,1,2),\n",
    "                Resnet1DBlock(128,1),\n",
    "                layers.Conv1D(256,1,2),\n",
    "                Resnet1DBlock(256,1),\n",
    "                # No activation\n",
    "                layers.Flatten(),\n",
    "                layers.Dense(latent_dim+latent_dim)\n",
    "\n",
    "            ]\n",
    "        )\n",
    "        self.decoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "                layers.Reshape(target_shape=(1,latent_dim)),\n",
    "                Resnet1DBlock(512,1,'decode'),\n",
    "                layers.Conv1DTranspose(512,1,1),\n",
    "                Resnet1DBlock(256,1,'decode'),\n",
    "                layers.Conv1DTranspose(256,1,1),\n",
    "                Resnet1DBlock(128,1,'decode'),\n",
    "                layers.Conv1DTranspose(128,1,1),\n",
    "                Resnet1DBlock(64,1,'decode'),\n",
    "                layers.Conv1DTranspose(64,1,1),\n",
    "                # No activation\n",
    "                layers.Conv1DTranspose(22500*10,1,1), #90001\n",
    "            ]\n",
    "        )\n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(200, self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n",
    "    @tf.function\n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "    @tf.function\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "    @tf.function\n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aec3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.0003,beta_1=0.9, beta_2=0.999,epsilon=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be731d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(\n",
    "         -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "          axis=raxis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3faecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_loss(model, x):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_logit = model.decode(z)\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1,2])\n",
    "    logpz = log_normal_pdf(z, 0., 0.)\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f7f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "    \n",
    "    \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "       This function computes the loss and gradients, and uses the latter to\n",
    "       update the model's parameters.\n",
    "     \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "            mean, logvar = model.encode(x)\n",
    "            z = model.reparameterize(mean, logvar)\n",
    "            x_logit = model.decode(z)\n",
    "            cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "            logpx_z = -tf.reduce_sum(cross_ent, axis=[1,2])\n",
    "            logpz = log_normal_pdf(z, 0., 0.)\n",
    "            logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "            loss_KL = -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                     tf.keras.losses.binary_crossentropy(x, x_logit)\n",
    "                 )\n",
    "            total_loss = reconstruction_loss+ loss_KL\n",
    "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f68540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "random_vector_for_generation = tf.random.normal(\n",
    "    shape=[num_examples_to_generate, latent_dim])\n",
    "model = CVAE(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9b9e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "\n",
    "def generate_and_save_images(model, epoch, test_sample, save):\n",
    "    mean, logvar = model.encode(test_sample)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    predictions = model.sample(z)\n",
    "    fig = plt.figure(figsize=(18, 15))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        wave = np.asarray(predictions[i], dtype=np.float32)\n",
    "        librosa.display.waveplot(wave[0], sr=22500)\n",
    "\n",
    "    # tight_layout minimizes the overlap between 2 sub-plots\n",
    "    plt.savefig('{}_{:04d}.png'.format(save, epoch))\n",
    "    plt.savefig('{}_{:04d}.png'.format(save, epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2467ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert BATCH_SIZE >= num_examples_to_generate\n",
    "for test_batch in test.take(1):\n",
    "    test_sample = test_batch[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb34d9d",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac011525",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "generate_and_save_images(model, 0, test_sample, 'wave')\n",
    "\n",
    "epochs = 4\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = time.time()\n",
    "    for train_x in train:\n",
    "        train_x = np.asarray(train_x, dtype=np.float32)[0]\n",
    "        train_step(model, train_x, optimizer)\n",
    "    end_time = time.time()\n",
    "\n",
    "    loss = tf.keras.metrics.Mean()\n",
    "    for test_x in test:\n",
    "        test_x = np.asarray(test_x)[0]\n",
    "        loss(compute_loss(model, test_x))\n",
    "    clear_output(wait=False)\n",
    "    elbo = -loss.result()\n",
    "    print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'.format(epoch,\n",
    "                                                                                   elbo, \n",
    "                                                                                   end_time - start_time\n",
    "                                                                                  ))\n",
    "    generate_and_save_images(model, \n",
    "                             epoch, \n",
    "                             test_sample, \n",
    "                             'wave')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece1c2e7",
   "metadata": {},
   "source": [
    "## Generated ASMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b48d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "save_asmr = []\n",
    "for test_data in test:\n",
    "    mean, logvar = model.encode(test_data)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    predictions = model.sample(z)\n",
    "    for pred in predictions:\n",
    "        wave = np.asarray(pred)\n",
    "        save_asmr.append(wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aeb61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "asmr1=save_asmr[0][0]\n",
    "ipd.Audio(asmr1,rate=22500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdc4bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "sf.write(\"asmr_heavyrain.wav\",asmr1,22500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6dc138",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"./asmr_heavy_rain.wav\"\n",
    "ipd.Audio(audio_path, 22500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a23daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "asmr2=save_asmr[1][0]\n",
    "ipd.Audio(asmr2,rate=22500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f401ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "asmr3=save_asmr[2][0]\n",
    "ipd.Audio(asmr3,rate=22500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673d380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "asmr4=save_asmr[3][0]\n",
    "ipd.Audio(asmr4,rate=22500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998b5fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "asmr5=save_asmr[4][0]\n",
    "ipd.Audio(asmr5,rate=22500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7919cb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "asmr6=save_asmr[5][0]\n",
    "ipd.Audio(asmr6,rate=22500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21380233",
   "metadata": {},
   "outputs": [],
   "source": [
    "asmr7=save_asmr[6][0]\n",
    "ipd.Audio(asmr7,rate=22500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082d7b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "asmr8=save_asmr[7][0]\n",
    "ipd.Audio(asmr7,rate=22500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03548e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(save_asmr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121d8567",
   "metadata": {},
   "source": [
    "## Gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5f2f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097bb7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_file = 'rain_vae.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "    filenames = glob.glob('rain*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeadda87",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed.embed_file(anim_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
