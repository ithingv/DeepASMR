{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "753c0516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 01:46:49.558094: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "# tensorflow \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Add\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccf63245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython import display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38cbcfc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 01:46:54.649341: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-13 01:46:54.669047: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-13 01:46:56.147506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 01:46:56.148195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-12-13 01:46:56.148231: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-13 01:46:56.184761: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-12-13 01:46:56.184873: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-12-13 01:46:56.206844: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-13 01:46:56.218138: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-13 01:46:56.245795: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-13 01:46:56.256943: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-12-13 01:46:56.259213: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-12-13 01:46:56.259389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 01:46:56.260164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 01:46:56.261807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "# gpu check\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e856a6",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6a0ea1",
   "metadata": {},
   "source": [
    "1) Residual Block : encoder, decoder 에 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8876c04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(layers.Layer): \n",
    "    def __init__(self, filters, kernel_size, type='encode'):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "    \n",
    "        if type=='encode':\n",
    "            self.conv1 = layers.Conv1D(filters, kernel_size, 2,padding=\"same\")\n",
    "            self.conv2 = layers.Conv1D(filters, kernel_size, 1,padding=\"same\")\n",
    "            self.norm1 = layers.BatchNormalization() # InstanceNormalization()\n",
    "            self.norm2 = layers.BatchNormalization() # InstanceNormalization()\n",
    "        \n",
    "        if type=='decode':\n",
    "            self.conv1 = layers.Conv1DTranspose(filters, kernel_size, 1,padding=\"same\")\n",
    "            self.conv2 = layers.Conv1DTranspose(filters, kernel_size, 1,padding=\"same\")\n",
    "            self.norm1 = layers.BatchNormalization()\n",
    "            self.norm2 = layers.BatchNormalization()\n",
    "        else:\n",
    "            return None\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        x = tf.nn.relu(inputs)\n",
    "       \n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = layers.LeakyReLU(0.4)(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = layers.LeakyReLU(0.4)(x)\n",
    "\n",
    "        x = Add()([x, inputs]) #residual layer\n",
    "        x = tf.nn.relu(x)\n",
    "        return x      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74541b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer): # VAE 정규분포 생성을 위한 sampling\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs                        # mean과 log variance\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_mean)))# normal distribution\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon \n",
    "    \n",
    "# Labmda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f9f0d6",
   "metadata": {},
   "source": [
    "## Logmelspectrogram class\n",
    "\n",
    "- layer 사이에 넣어서 저장할 수 있음.\n",
    "\n",
    "- \n",
    "__init__(): 환경설정을 저장합니다. \n",
    "\n",
    "build(): weight를 정의합니다.\n",
    "\n",
    "call(): mel-spectrogram layer를 input tensor에 적용하는 메소드. audio input-tensor가 mel-spectrogram으로 바뀜."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "557b0b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/how-to-easily-process-audio-on-your-gpu-with-tensorflow-2d9d91360f06\n",
    "\n",
    "_FFT_SIZE = 1024\n",
    "_HOP_SIZE = 512\n",
    "_N_MEL_BINS = 64\n",
    "_N_SPECTROGRAM_BINS = (_FFT_SIZE // 2) + 1\n",
    "_F_MIN = 0.0\n",
    "_SAMPLE_RATE = 16000\n",
    "_F_MAX = _SAMPLE_RATE / 2\n",
    "\n",
    "\n",
    "class LogMelSpectrogram(tf.keras.layers.Layer):\n",
    "    \"\"\"Compute log-magnitude mel-scaled spectrograms.\"\"\"\n",
    "\n",
    "    def __init__(self, sample_rate, fft_size, hop_size, n_mels,\n",
    "                 f_min=0.0, f_max=None, **kwargs):\n",
    "        super(LogMelSpectrogram, self).__init__(**kwargs)\n",
    "        self.sample_rate = sample_rate\n",
    "        self.fft_size = fft_size\n",
    "        self.hop_size = hop_size\n",
    "        self.n_mels = n_mels\n",
    "        self.f_min = f_min\n",
    "        self.f_max = f_max if f_max else sample_rate / 2\n",
    "        self.mel_filterbank = tf.signal.linear_to_mel_weight_matrix(\n",
    "            num_mel_bins=self.n_mels,\n",
    "            num_spectrogram_bins=fft_size // 2 + 1,\n",
    "            sample_rate=self.sample_rate,\n",
    "            lower_edge_hertz=self.f_min,\n",
    "            upper_edge_hertz=self.f_max)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.non_trainable_weights.append(self.mel_filterbank)\n",
    "        super(LogMelSpectrogram, self).build(input_shape)\n",
    "\n",
    "    def call(self, waveforms):\n",
    "        \"\"\"Forward pass.\n",
    "        Parameters\n",
    "        ----------\n",
    "        waveforms : tf.Tensor, shape = (None, n_samples)\n",
    "            A Batch of mono waveforms.\n",
    "        Returns\n",
    "        -------\n",
    "        log_mel_spectrograms : (tf.Tensor), shape = (None, time, freq, ch)\n",
    "            The corresponding batch of log-mel-spectrograms\n",
    "        \"\"\"\n",
    "        def _tf_log10(x):\n",
    "            numerator = tf.math.log(x)\n",
    "            denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))\n",
    "            return numerator / denominator\n",
    "\n",
    "        def power_to_db(magnitude, amin=1e-16, top_db=80.0):\n",
    "            \"\"\"\n",
    "            https://librosa.github.io/librosa/generated/librosa.core.power_to_db.html\n",
    "            \"\"\"\n",
    "            ref_value = tf.reduce_max(magnitude)\n",
    "            log_spec = 10.0 * _tf_log10(tf.maximum(amin, magnitude))\n",
    "            log_spec -= 10.0 * _tf_log10(tf.maximum(amin, ref_value))\n",
    "            log_spec = tf.maximum(log_spec, tf.reduce_max(log_spec) - top_db)\n",
    "\n",
    "            return log_spec\n",
    "\n",
    "        spectrograms = tf.signal.stft(waveforms,\n",
    "                                      frame_length=self.fft_size,\n",
    "                                      frame_step=self.hop_size,\n",
    "                                      pad_end=False)\n",
    "\n",
    "        magnitude_spectrograms = tf.abs(spectrograms)\n",
    "\n",
    "        mel_spectrograms = tf.matmul(tf.square(magnitude_spectrograms),\n",
    "                                     self.mel_filterbank)\n",
    "\n",
    "        log_mel_spectrograms = power_to_db(mel_spectrograms)\n",
    "\n",
    "        # add channel dimension\n",
    "        log_mel_spectrograms = tf.expand_dims(log_mel_spectrograms, 3)\n",
    "\n",
    "        return log_mel_spectrograms\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'fft_size': self.fft_size,\n",
    "            'hop_size': self.hop_size,\n",
    "            'n_mels': self.n_mels,\n",
    "            'sample_rate': self.sample_rate,\n",
    "            'f_min': self.f_min,\n",
    "            'f_max': self.f_max,\n",
    "        }\n",
    "        config.update(super(LogMelSpectrogram, self).get_config())\n",
    "\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9e91a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InverseSTFT(layers.Layer):\n",
    "    \"\"\"An inverse-STFT layer.\n",
    "    If `output_data_format == 'channels_last'`, the output shape is (batch, time, channel)\n",
    "    If `output_data_format == 'channels_first'`, the output shape is (batch, channel, time)\n",
    "    Note that the result of inverse STFT could be longer than the original signal due to the padding. Do check the\n",
    "    size of the result by yourself and trim it if needed.\n",
    "    Args:\n",
    "        n_fft (int): Number of FFTs. Defaults to `2048`\n",
    "        win_length (`int` or `None`): Window length in sample. Defaults to `n_fft`.\n",
    "        hop_length (`int` or `None`): Hop length in sample between analysis windows. Defaults to `n_fft // 4` following Librosa.\n",
    "        forward_window_name (str or None): *Name* of `tf.signal` function that *was* used in the forward STFT.\n",
    "            Defaults to `hann_window`, assuming `tf.signal.hann_window` was used.\n",
    "            Window availability depends on Tensorflow version. More details are at `kapre.backend.get_window()`.\n",
    "        input_data_format (`str`): the data format of input STFT batch\n",
    "            `'channels_last'` if you want `(batch, time, frequency, channels)`\n",
    "            `'channels_first'` if you want `(batch, channels, time, frequency)`\n",
    "            Defaults to the setting of your Keras configuration. (tf.keras.backend.image_data_format())\n",
    "        output_data_format (`str`): the audio data format of output waveform batch.\n",
    "            `'channels_last'` if it's `(batch, time, channels)`\n",
    "            `'channels_first'` if it's `(batch, channels, time)`\n",
    "            Defaults to the setting of your Keras configuration. (tf.keras.backend.image_data_format())\n",
    "        **kwargs: Keyword args for the parent keras layer (e.g., `name`)\n",
    "    Example:\n",
    "        ::\n",
    "            input_shape = (3, 513, 1)  # 3 frames, 513 frequency bins, 1 channel\n",
    "            # and input dtype is complex\n",
    "            model = Sequential()\n",
    "            model.add(kapre.InverseSTFT(n_fft=1024, hop_length=512, input_shape=input_shape))\n",
    "            # now the shape is (batch, time=2048, ch=1)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fft=2048,\n",
    "        win_length=None,\n",
    "        hop_length=None,\n",
    "        forward_window_name=None,\n",
    "        input_data_format='default',\n",
    "        output_data_format='default',\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(InverseSTFT, self).__init__(**kwargs)\n",
    "\n",
    "        backend.validate_data_format_str(input_data_format)\n",
    "        backend.validate_data_format_str(output_data_format)\n",
    "\n",
    "        if win_length is None:\n",
    "            win_length = n_fft\n",
    "        if hop_length is None:\n",
    "            hop_length = win_length // 4\n",
    "\n",
    "        self.n_fft = n_fft\n",
    "        self.win_length = win_length\n",
    "        self.hop_length = hop_length\n",
    "        self.forward_window_name = forward_window_name\n",
    "        self.window_fn = tf.signal.inverse_stft_window_fn(\n",
    "            frame_step=hop_length, forward_window_fn=backend.get_window_fn(forward_window_name)\n",
    "        )\n",
    "\n",
    "        idt, odt = input_data_format, output_data_format\n",
    "        self.output_data_format = K.image_data_format() if odt == _CH_DEFAULT_STR else odt\n",
    "        self.input_data_format = K.image_data_format() if idt == _CH_DEFAULT_STR else idt\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        Compute inverse STFT of the input STFT.\n",
    "        Args:\n",
    "            x (complex `Tensor`): batch of STFTs, (batch, ch, time, freq) or (batch, time, freq, ch) depending on `input_data_format`\n",
    "        Return:\n",
    "            (`float`): audio signals of x. Shape: 1D batch shape. I.e., (batch, time, ch) or (batch, ch, time) depending on `output_data_format`\n",
    "        \"\"\"\n",
    "        stfts = x  # (batch, ch, time, freq) if input_data_format == 'channels_first'.\n",
    "        # (batch, time, freq, ch) if input_data_format == 'channels_last'.\n",
    "\n",
    "        # this is needed because tf.signal.stft lives in channels_first land.\n",
    "        if self.input_data_format == _CH_LAST_STR:\n",
    "            stfts = tf.transpose(stfts, perm=(0, 3, 1, 2))  # now always (b, ch, t, f)\n",
    "\n",
    "        waveforms = tf.signal.inverse_stft(\n",
    "            stfts=stfts,\n",
    "            frame_length=self.win_length,\n",
    "            frame_step=self.hop_length,\n",
    "            fft_length=self.n_fft,\n",
    "            window_fn=self.window_fn,\n",
    "            name='%s_tf.signal.istft' % self.name,\n",
    "        )  # (batch, ch, time)\n",
    "\n",
    "        if self.output_data_format == _CH_LAST_STR:\n",
    "            waveforms = tf.transpose(waveforms, perm=(0, 2, 1))  # (batch, time, ch)\n",
    "\n",
    "        return waveforms\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(InverseSTFT, self).get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                'n_fft': self.n_fft,\n",
    "                'win_length': self.win_length,\n",
    "                'hop_length': self.hop_length,\n",
    "                'forward_window_name': self.forward_window_name,\n",
    "                'input_data_format': self.input_data_format,\n",
    "                'output_data_format': self.output_data_format,\n",
    "            }\n",
    "        )\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cee41e",
   "metadata": {},
   "source": [
    "# Encoder, Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3adb7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder\n",
    "\n",
    "def get_encoder(latent_dim=2, sample_rate=16000, duration=4,\n",
    "              fft_size=_FFT_SIZE, hop_size=_HOP_SIZE, n_mels=_N_MEL_BINS):\n",
    "    encoder_inputs = layers.Input(shape=(441000,)) # 수정 요망\n",
    "#     print(encoder_inputs)\n",
    "    x = LogMelSpectrogram(sample_rate, fft_size, hop_size, n_mels)(encoder_inputs)\n",
    "#     print(x)\n",
    "    x = layers.Conv2D(64, (3,n_mels), activation='relu')(x)\n",
    "#     print(x)\n",
    "    x = ResidualBlock(64, 1)(x)\n",
    "    x = layers.Conv2D(128,1, 2, activation='relu')(x)\n",
    "    x = ResidualBlock(128, 1)(x)\n",
    "    x = layers.Conv2D(128, 1, 2)(x)\n",
    "    x = ResidualBlock(128, 1)(x)\n",
    "    x = layers.Conv2D(256, 1, 2)(x)\n",
    "    x = ResidualBlock(256, 1)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x) \n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    return keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5e7b5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_encoder().output[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60194410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "def get_decoder(latent_dim=2):\n",
    "    print(get_encoder().output[2])\n",
    "    latent_inputs = keras.Input(shape=get_encoder().output[2].shape[1:])\n",
    "    print(latent_inputs)\n",
    "    x = layers.Reshape(target_shape=(1,latent_dim))(latent_inputs)\n",
    "    x = ResidualBlock(256,1,'decode')(x)\n",
    "    x = layers.Conv2DTranspose(256, 1, 2)(x)\n",
    "    x = ResidualBlock(256,1,'decode')(x)\n",
    "    x = layers.Conv2DTranspose(128, 1, 2)(x)\n",
    "    x = ResidualBlock(128,1,'decode')(x)\n",
    "    x = layers.Conv2DTranspose(128,1,2)(x)\n",
    "    x = ResidualBlock(64,1,'decode')(x)\n",
    "    x = layers.Conv2DTranspose(64, (3,n_mels), activation='relu')(x)\n",
    "\n",
    "    decoder_outputs = layers.Conv2DTranspose(441000,1,1)(x)\n",
    "    \n",
    "    return keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "078ee610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bbba99",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "110a9491",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/home/jsryu1228/crawling/temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99342389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "# natsorted가 무엇인가요?\n",
    "\n",
    "asmr_list = np.array(natsorted(os.listdir(BASE_DIR)))\n",
    "data = [BASE_DIR + '/%s' % (x) for x in asmr_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b419d736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 파일이 10초가 아닐 수 있기 때문에 제거\n",
    "data = data[:len(data) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd10b29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav_load(asmr):\n",
    "    y, sampling_rate = librosa.load(asmr, sr=44100, offset=0.0, duration=10)\n",
    "    return y\n",
    "\n",
    "map_func = lambda file: tf.compat.v1.py_func(wav_load, [file], [tf.float32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f08b9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_3039/1797789595.py:5: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 02:06:23.949240: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-13 02:06:23.949764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 02:06:23.950533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-12-13 02:06:23.950579: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-13 02:06:23.950635: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-12-13 02:06:23.950650: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-12-13 02:06:23.950663: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-13 02:06:23.950675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-13 02:06:23.950688: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-13 02:06:23.950704: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-12-13 02:06:23.950717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-12-13 02:06:23.950805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 02:06:23.951430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 02:06:23.952010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-12-13 02:06:23.953501: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-13 02:06:25.486794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-13 02:06:25.486836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-12-13 02:06:25.486847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-12-13 02:06:25.489221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 02:06:25.490002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 02:06:25.490637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-13 02:06:25.491226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14762 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(data)\n",
    "    .map(map_func, num_parallel_calls=AUTOTUNE)\n",
    "    .shuffle(3)\n",
    "    .batch(8,drop_remainder =True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77d9354",
   "metadata": {},
   "source": [
    "모양 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ae80464",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(8, 441000), dtype=float32, numpy=\n",
      "array([[-1.4038086e-03, -3.6621094e-04,  3.5095215e-04, ...,\n",
      "        -1.0223389e-03, -1.3275146e-03, -1.0070801e-03],\n",
      "       [-1.2664795e-02, -1.2588501e-02, -1.2512207e-02, ...,\n",
      "        -4.4403076e-03, -2.1514893e-03, -2.7923584e-03],\n",
      "       [ 6.1035156e-05,  1.3275146e-03,  2.6550293e-03, ...,\n",
      "        -1.2374878e-02, -1.2390137e-02, -1.2527466e-02],\n",
      "       ...,\n",
      "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
      "        -3.2806396e-03, -2.9602051e-03, -2.2277832e-03],\n",
      "       [-9.7351074e-03, -8.9111328e-03, -8.6059570e-03, ...,\n",
      "         2.0141602e-03,  2.2735596e-03,  2.2277832e-03],\n",
      "       [ 2.1514893e-03,  2.3040771e-03,  2.1667480e-03, ...,\n",
      "         2.8808594e-02,  2.9144287e-02,  2.8640747e-02]], dtype=float32)>,)\n",
      "(<tf.Tensor: shape=(8, 441000), dtype=float32, numpy=\n",
      "array([[ 4.5776367e-04,  4.8828125e-04,  6.2561035e-04, ...,\n",
      "        -1.3870239e-02, -1.4862061e-02, -1.4617920e-02],\n",
      "       [ 2.7755737e-02,  2.6885986e-02,  2.6199341e-02, ...,\n",
      "         6.1035156e-05,  7.0190430e-04,  6.1035156e-05],\n",
      "       [ 8.8500977e-04,  1.0528564e-03,  1.3122559e-03, ...,\n",
      "         1.1047363e-02,  1.0986328e-02,  1.0787964e-02],\n",
      "       ...,\n",
      "       [ 4.4250488e-03,  3.9978027e-03,  3.4637451e-03, ...,\n",
      "        -2.4108887e-03, -2.8533936e-03, -3.0975342e-03],\n",
      "       [-2.4414062e-04,  2.1362305e-04,  8.2397461e-04, ...,\n",
      "        -2.5329590e-03, -2.3651123e-03, -2.1362305e-03],\n",
      "       [-1.8310547e-04, -1.5258789e-05, -6.5612793e-04, ...,\n",
      "         5.3863525e-03,  4.8370361e-03,  4.6234131e-03]], dtype=float32)>,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 02:06:28.999167: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-12-13 02:06:29.003595: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataset.take(2):\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de8ec18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_point_cb = ModelCheckpoint('vae_rain_50.h5', save_best_only=True)\n",
    "early_stopping_cb = EarlyStopping(patience=5, monitor='reconstruction_loss', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c83fb34a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 2), dtype=tf.float32, name=None), name='sampling_20/add:0', description=\"created by layer 'sampling_20'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 2), dtype=tf.float32, name='input_26'), name='input_26', description=\"created by layer 'input_26'\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /tmp/ipykernel_3039/844975756.py:30 call  *\n        x = Add()([x, inputs]) #residual layer\n    /home/jsryu1228/anaconda3/envs/asmr/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:1008 __call__  **\n        self._maybe_build(inputs)\n    /home/jsryu1228/anaconda3/envs/asmr/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:2710 _maybe_build\n        self.build(input_shapes)  # pylint:disable=not-callable\n    /home/jsryu1228/anaconda3/envs/asmr/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py:272 wrapper\n        output_shape = fn(instance, input_shape)\n    /home/jsryu1228/anaconda3/envs/asmr/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py:112 build\n        output_shape = self._compute_elemwise_op_output_shape(output_shape, shape)\n    /home/jsryu1228/anaconda3/envs/asmr/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py:85 _compute_elemwise_op_output_shape\n        'together with shapes ' + str(shape1) + ' ' + str(shape2))\n\n    ValueError: Operands could not be broadcast together with shapes (1, 256) (1, 2)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3039/1856968991.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# conv2d로 바꾸고, 내부 dimension도 바꿔야 함.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3039/4294841265.py\u001b[0m in \u001b[0;36mget_decoder\u001b[0;34m(latent_dim)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResidualBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'decode'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2DTranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResidualBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'decode'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/asmr/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/asmr/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/asmr/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/asmr/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/asmr/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /tmp/ipykernel_3039/844975756.py:30 call  *\n        x = Add()([x, inputs]) #residual layer\n    /home/jsryu1228/anaconda3/envs/asmr/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:1008 __call__  **\n        self._maybe_build(inputs)\n    /home/jsryu1228/anaconda3/envs/asmr/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:2710 _maybe_build\n        self.build(input_shapes)  # pylint:disable=not-callable\n    /home/jsryu1228/anaconda3/envs/asmr/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py:272 wrapper\n        output_shape = fn(instance, input_shape)\n    /home/jsryu1228/anaconda3/envs/asmr/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py:112 build\n        output_shape = self._compute_elemwise_op_output_shape(output_shape, shape)\n    /home/jsryu1228/anaconda3/envs/asmr/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py:85 _compute_elemwise_op_output_shape\n        'together with shapes ' + str(shape1) + ' ' + str(shape2))\n\n    ValueError: Operands could not be broadcast together with shapes (1, 256) (1, 2)\n"
     ]
    }
   ],
   "source": [
    "encoder = get_encoder()\n",
    "decoder = get_decoder()\n",
    "# conv2d로 바꾸고, 내부 dimension도 바꿔야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83134ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "vae.fit(\n",
    "    train_dataset\n",
    "    ,epochs=50, batch_size=32, callbacks=[early_stopping_cb])\n",
    "#, callbacks=[check_point_cb, early_stopping_cb, lr_schduler_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad43d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original\n",
    "\n",
    "test_audio_path = '/home/jsryu1228/crawling/temp/1000.wav'\n",
    "test_data, sr = librosa.load(test_audio_path, sr=44100, dtype=np.float32)\n",
    "\n",
    "# original audio test\n",
    "\n",
    "from IPython import display as ipd\n",
    "ipd.Audio(test_data, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6152706",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_asmr = []\n",
    "for test_data in data[100:104]:\n",
    "    mean, logvar, z = vae.encode(test_data)\n",
    "    prediction = vae.decoder.predict(z[0])\n",
    "    for pred in predictions:\n",
    "        wave = np.asarray(pred)\n",
    "        save_asmr.append(wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d9a1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, sr = librosa.load(test_audio_path, sr=44100, dtype=np.float32)\n",
    "test_data = test_data.reshape(1,44100*10)\n",
    "test_data = np.expand_dims(test_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebb4bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output = vae.encoder.predict(test_data)\n",
    "prediction = vae.decoder.predict(encoder_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1a0399",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = prediction.reshape(44100*10,)\n",
    "ipd.Audio(prediction, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73ed8b0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: checkpoint/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3020/3807286229.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'checkpoint'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/asmr/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/asmr/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    112\u001b[0m                   (export_dir,\n\u001b[1;32m    113\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: checkpoint/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "model = load_model('checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cef9b93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec 12 04:36:36 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.86       Driver Version: 470.86       CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   36C    P0    40W / 300W |      2MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e981e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
